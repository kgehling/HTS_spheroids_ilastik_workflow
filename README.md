# High-throughput-screening approach with spheroids under various conditions using the ilastik software to process the imaging data acquired during the screening.

Steps taken beforehand: 
- ilastik pixel classification workflow
- ilastik object classification workflow exporting the data as csv files without changing the default export suffix (.e.g., file still ends with table.csv)

# 1. Step: process_ilastik_output_function
- helps to merge the output tables into one large data frame by automating tasks such as data loading, metadata extraction, filtering, measurement conversion, and saving
- function is adapted for images that were taken with the Cytation5 multi-mode reader


DETAILS:

1. Input Parameters: The function takes several input parameters:
- path: This is the path where the ilastik output files are located.
- image_resolution: This parameter specifies the resolution of the images used in ilastik, which can be either "4x" or "2x".
- predicted_class (optional): This parameter allows filtering the data based on a predicted class, typically used in machine learning scenarios.

3. Pixel Factor Calculation: It internally calculates a pixel factor based on the image resolution provided. The pixel factor is essential for converting pixel measurements to physical measurements (e.g., micrometers) and is different for each microscope! This script is adapted for the Cytation5 multimode reader with either a 2x or 4x magnification objective.

4. Data Processing:
- It loads and processes the output data files generated by ilastik.
- It combines the metadata from the file names with the data from the CSV files.
- Optionally, it filters the data based on a predicted class if specified.
- It performs additional calculations on the data, such as converting pixel measurements to micrometers and millimeters using the calculated pixel factor.

5. Output:
- The processed data is saved as a CSV file in the same directory where the input files are located.
- The function returns the processed data as a tibble (a tidyverse-friendly data frame), which can be further used for analysis or visualization.






# 2. Step: Import_metadata
Adjustments for Usability and Flexibility:
The script is structured to be modular and reusable. Functions like preprocess_plate and convert_time_stamp_to_hours can be called as needed, depending on the number of plates and the specific requirements of the analysis.
It includes options to filter the data based on the predicted class and to add identifiers to distinguish between data from different plates or conditions within the experiment.

OUTSIDE R | preparations for the plater package:
add here

DETAILS
1. Input Parameters preprocess_plate function:
- data_path: The file path to the merged table data for a plate.
- pattern_path: The file path to the experiment design pattern for the plate.
- cell_type: The type of cell in the plate (e.g., "HepG2").
- plate_id (optional): An identifier for the plate (e.g., "LPG_1"), used to distinguish between different plates in the dataset.
- predicted_class (optional): A filter for the predicted class column (e.g., "Spheroid") to include only specific classifications in the analysis.

Description:
This function reads and preprocesses data from a plate, including filtering, merging with metadata, and adding additional information like the cell type and a self-determined identifier. It optionally filters entries based on the predicted Object class (as defined in the ilastik Object classification workflow).


2. Input Parameters Convert Time Stamp to Hours function:
- df: The data frame containing time_stamp information, this info is extracted from the image ID.
- interval: The time interval (in hours) between measurements, typically fixed but adjustable for flexibility.

Description:
Converts time stamps in the data to numeric hours since the experiment's start, with the first measurement explicitly set to 1 hour and subsequent measurements calculated based on the given interval.

3. Merge Data from Multiple Plates:
The script allows for processing multiple plates by calling preprocess_plate for each one and then merging all resulting data frames into one large data frame. This is facilitated by binding rows from each plate's processed data frame, creating a unified data set that contains data across all processed plates.

